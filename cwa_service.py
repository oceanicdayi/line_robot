# cwa_service.py (Final Defensive Parsing Version)
import requests
import re
import pandas as pd
from datetime import datetime, timedelta, timezone
from config import CWA_API_KEY, CWA_ALARM_API, CWA_SIGNIFICANT_API

TAIPEI_TZ = timezone(timedelta(hours=8))

def _to_float(x):
    if x is None: return None
    s = str(x).strip()
    m = re.search(r"[-+]?\d+(?:\.\d+)?", s)
    return float(m.group()) if m else None

def _parse_cwa_time(s: str) -> tuple[str, str]:
    if not s: return ("æœªçŸ¥", "æœªçŸ¥")
    dt_utc = None
    try:
        dt_utc = datetime.fromisoformat(s.replace("Z", "+00:00"))
    except ValueError:
        try:
            dt_local = datetime.strptime(s, "%Y-%m-%d %H:%M:%S")
            dt_local = dt_local.replace(tzinfo=TAIPEI_TZ)
            dt_utc = dt_local.astimezone(timezone.utc)
        except Exception:
            return (s, "æœªçŸ¥")
    if dt_utc:
        tw_str = dt_utc.astimezone(TAIPEI_TZ).strftime("%Y-%m-%d %H:%M")
        utc_str = dt_utc.astimezone(timezone.utc).strftime("%Y-%m-%d %H:%M")
        return (tw_str, utc_str)
    return (s, "æœªçŸ¥")

def fetch_cwa_alarm_list(limit: int = 5) -> str:
    try:
        r = requests.get(CWA_ALARM_API, timeout=10)
        r.raise_for_status()
        payload = r.json()
    except Exception as e:
        return f"âŒ åœ°éœ‡é è­¦æŸ¥è©¢å¤±æ•—ï¼š{e}"
    items = payload.get("data", [])
    if not items: return "âœ… ç›®å‰æ²’æœ‰åœ°éœ‡é è­¦ã€‚"
    def _key(it):
        try: return datetime.fromisoformat(it.get("originTime", "").replace("Z", "+00:00"))
        except: return datetime.min.replace(tzinfo=timezone.utc)
    items = sorted(items, key=_key, reverse=True)
    lines = ["ðŸš¨ åœ°éœ‡é è­¦ï¼ˆæœ€æ–°ï¼‰:", "-" * 20]
    for it in items[:limit]:
        mag = _to_float(it.get("magnitudeValue"))
        depth = _to_float(it.get("depth"))
        tw_str, _ = _parse_cwa_time(it.get("originTime", ""))
        identifier = str(it.get('identifier', 'â€”')).replace('{', '{{').replace('}', '}}')
        msg_type = str(it.get('msgType', 'â€”')).replace('{', '{{').replace('}', '}}')
        msg_no = str(it.get('msgNo', 'â€”')).replace('{', '{{').replace('}', '}}')
        location_desc_list = it.get('locationDesc')
        areas_str = ", ".join(str(area) for area in location_desc_list) if isinstance(location_desc_list, list) and location_desc_list else "â€”"
        areas = areas_str.replace('{', '{{').replace('}', '}}')
        mag_str = f"{mag:.1f}" if mag is not None else "â€”"
        depth_str = f"{depth:.0f}" if depth is not None else "â€”"
        lines.append(
            f"äº‹ä»¶: {identifier} | é¡žåž‹: {msg_type}#{msg_no}\n"
            f"è¦æ¨¡/æ·±åº¦: M{mag_str} / {depth_str} km\n"
            f"æ™‚é–“: {tw_str}ï¼ˆå°ç£ï¼‰\n"
            f"åœ°é»ž: {areas}"
        )
    return "\n\n".join(lines).strip()

def _parse_significant_earthquakes(obj: dict) -> pd.DataFrame:
    records = obj.get("records", {})
    quakes = records.get("Earthquake", [])
    rows = []
    for q in quakes:
        # [åµéŒ¯] å¦‚æžœéœ€è¦ï¼Œå¯ä»¥å–æ¶ˆä¸‹é¢é€™è¡Œçš„è¨»è§£ï¼Œå®ƒæœƒåœ¨ Log ä¸­å°å‡ºæœ€åŽŸå§‹çš„è³‡æ–™
        # print(f"åŽŸå§‹åœ°éœ‡è³‡æ–™: {q}") 
        
        ei = q.get("EarthquakeInfo", {})
        
        # [ä¿®æ­£] ä½¿ç”¨æ›´ç©©å¥çš„æ–¹å¼å–å¾—æ‰€æœ‰è³‡æ–™ï¼Œæª¢æŸ¥æ‰€æœ‰å·²çŸ¥çš„å¤§å°å¯«å’Œå‚™ç”¨åç¨±
        epic = ei.get("Epicenter") or ei.get("epicenter") or {}
        mag_info = ei.get("Magnitude") or ei.get("magnitude") or ei.get("EarthquakeMagnitude") or {}
        depth_raw = ei.get("FocalDepth") or ei.get("depth") or ei.get("Depth")
        mag_raw = mag_info.get("MagnitudeValue") or mag_info.get("magnitudeValue") or mag_info.get("Value") or mag_info.get("value")
        
        rows.append({
            "ID": q.get("EarthquakeNo"), "Time": ei.get("OriginTime"),
            "Lat": _to_float(epic.get("EpicenterLatitude") or epic.get("epicenterLatitude")),
            "Lon": _to_float(epic.get("EpicenterLongitude") or epic.get("epicenterLongitude")),
            "Depth": _to_float(depth_raw), 
            "Magnitude": _to_float(mag_raw),
            "Location": epic.get("Location") or epic.get("location"), 
            "URL": q.get("Web") or q.get("ReportURL"),
        })
        
    df = pd.DataFrame(rows)
    if not df.empty and "Time" in df.columns:
        df["Time"] = pd.to_datetime(df["Time"], errors="coerce", utc=True).dt.tz_convert(TAIPEI_TZ)
    return df

def fetch_significant_earthquakes(days: int = 7, limit: int = 5) -> str:
    if not CWA_API_KEY: return "âŒ é¡¯è‘—åœ°éœ‡æŸ¥è©¢å¤±æ•—ï¼šç®¡ç†è€…å°šæœªè¨­å®š CWA_API_KEYã€‚"
    now = datetime.now(timezone.utc)
    time_from = (now - timedelta(days=days)).strftime("%Y-%m-%d")
    params = {"Authorization": CWA_API_KEY, "format": "JSON", "timeFrom": time_from}
    try:
        r = requests.get(CWA_SIGNIFICANT_API, params=params, timeout=15)
        r.raise_for_status()
        data = r.json()
        df = _parse_significant_earthquakes(data)
        if df.empty: return f"âœ… éŽåŽ» {days} å¤©å…§æ²’æœ‰é¡¯è‘—æœ‰æ„Ÿåœ°éœ‡å ±å‘Šã€‚"
        df = df.sort_values(by="Time", ascending=False).head(limit)
        lines = [f"ðŸš¨ CWA æœ€æ–°é¡¯è‘—æœ‰æ„Ÿåœ°éœ‡ (è¿‘{days}å¤©å†…):", "-" * 20]
        for _, row in df.iterrows():
            mag_str = f"{row['Magnitude']:.1f}" if pd.notna(row['Magnitude']) else "â€”"
            depth_str = f"{row['Depth']:.0f}" if pd.notna(row['Depth']) else "â€”"
            lines.append(
                f"æ™‚é–“: {row['Time'].strftime('%Y-%m-%d %H:%M') if pd.notna(row['Time']) else 'â€”'}\n"
                f"åœ°é»ž: {row['Location'] or 'â€”'}\n"
                f"è¦æ¨¡: M{mag_str} | æ·±åº¦: {depth_str} km\n"
                f"å ±å‘Š: {row['URL'] or 'ç„¡'}"
            )
        return "\n\n".join(lines)
    except Exception as e:
        return f"âŒ é¡¯è‘—åœ°éœ‡æŸ¥è©¢å¤±æ•—ï¼š{e}"

def fetch_latest_significant_earthquake() -> dict | None:
    try:
        if not CWA_API_KEY: raise ValueError("éŒ¯èª¤ï¼šå°šæœªè¨­å®š CWA_API_KEY Secretã€‚")
        params = {"Authorization": CWA_API_KEY, "format": "JSON", "limit": 1, "orderby": "OriginTime desc"}
        r = requests.get(CWA_SIGNIFICANT_API, params=params, timeout=15)
        r.raise_for_status()
        data = r.json()
        df = _parse_significant_earthquakes(data)
        if df.empty: return None

        latest_eq_data = df.iloc[0].to_dict()
        
        quakes = data.get("records", {}).get("Earthquake", [])
        if quakes:
            latest_eq_data["ImageURL"] = quakes[0].get("ReportImageURI")

        if pd.notna(latest_eq_data.get("Time")):
            latest_eq_data["TimeStr"] = latest_eq_data["Time"].strftime('%Y-%m-%d %H:%M')

        return latest_eq_data
    except Exception as e:
        raise e

